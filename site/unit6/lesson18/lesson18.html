
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Abdulrahman Altahhan, 2024.">
      
      
      
        <link rel="prev" href="../../unit5/lesson17/lesson17.html">
      
      
      
      <link rel="icon" href="../../../docs/img/favicon.jpg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.4">
    
    
      
        <title>18. Application on Games(optional) - Reinforcement Learning for Autonomous Agents..</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8608ea7d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#lesson-18-rl-application-on-games" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
            
    <div id="versionIndicator"><b>Version:</b> 04.06.21.a</div>
    <img id="customlogo" src="../../../img/logo.svg" alt="University of Leeds logo.">

          </div>
          
        </aside>
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../index.html" title="Reinforcement Learning for Autonomous Agents.." class="md-header__button md-logo" aria-label="Reinforcement Learning for Autonomous Agents.." data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Reinforcement Learning for Autonomous Agents..
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              18. Application on Games(optional)
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../index.html" class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../unit1/lesson1/lesson1.html" class="md-tabs__link">
          
  
  Unit 1

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../unit2/lesson5/lesson5.html" class="md-tabs__link">
          
  
  Unit 2

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../unit3/lesson8/lesson8.html" class="md-tabs__link">
          
  
  Unit 3

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../unit4/lesson12/lesson12.html" class="md-tabs__link">
          
  
  Unit 4

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../unit5/lesson15/lesson15.html" class="md-tabs__link">
          
  
  Unit 5

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="lesson18.html" class="md-tabs__link">
          
  
  Unit 6

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../index.html" title="Reinforcement Learning for Autonomous Agents.." class="md-nav__button md-logo" aria-label="Reinforcement Learning for Autonomous Agents.." data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Reinforcement Learning for Autonomous Agents..
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Unit 1
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Unit 1
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit1/lesson1/lesson1.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1. Tabular Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit1/lesson2/lesson2.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2. K-Arm Bandit
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit1/lesson3/lesson3.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. MDP
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit1/lesson4/lesson4.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. ROS
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Unit 2
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Unit 2
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit2/lesson5/lesson5.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5. Dynamic Programming
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit2/lesson6/lesson6.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6. Monte Carlo
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit2/lesson7/lesson7.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7. Mobile Robots
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Unit 3
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Unit 3
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit3/lesson8/lesson8.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8. Temporal Difference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit3/lesson9/lesson9.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9. n-Step Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit3/lesson10/lesson10.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    10. Planning in RL(optional)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit3/lesson11/lesson11.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    11. Localisation and SLAM
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Unit 4
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Unit 4
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit4/lesson12/lesson12.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    12. Function Approximation Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit4/lesson13/lesson13.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    13. Linear Approximation for Prediction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit4/lesson14/lesson14.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    14. Linear Approximation for Control
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Unit 5
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Unit 5
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit5/lesson15/lesson15.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    15. Linear Approximation with Eligibility Traces(prediction and control)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit5/lesson16/lesson16.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    16. Nonlinear Approximation for Control
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../unit5/lesson17/lesson17.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    17. Application on Robot Navigation
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Unit 6
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Unit 6
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    18. Application on Games(optional)
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="lesson18.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    18. Application on Games(optional)
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#dependencies" class="md-nav__link">
    <span class="md-ellipsis">
      Dependencies
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#dependencies" class="md-nav__link">
    <span class="md-ellipsis">
      Dependencies
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<p>The notebook uses a library of functionality in RL that aims for simplicity and general insight into how algorithms work, these libraries are written from scratch using standard Python libraries (numpy, matplotlib etc.).
Please note that you will need permission from the author to use the code for research, commercially or otherwise.</p>
<h1 id="lesson-18-rl-application-on-games">Lesson 18: RL Application on Games</h1>
<p><strong>Learning outcomes</strong>
1. understand how to create a simple wrapper for a Gym environment to take advantage of its provided functionality
1. understand how to integrate our previous classes with Gym to combine them in a powerful way
1. appreciate the intricacy of applying RL to different domains such as games and robotics
1. build on previous concepts to come up with suitable and sometimes novel algorithms to solve a problem at hand
1. understand how to combine deep reinforcement learning with deep learning to create a powerful framework that allows automatic agent learning by observation or self-play.
1. understand how a replay buffer helps us to come closer to supervised learning and appreciate the important role it plays in reaching convergence for difficult problems that involve image processing and reinforcement learning</p>
<h2 id="dependencies">Dependencies</h2>
<p>Let us first install the gym environment and other dependencies including tensorflow and keras.</p>
<h1 id="gym">gym</h1>
<p>!pip3 install gym
!pip3 install pygame
!pip3 install pyglet
!pip3 install ale-py
!pip3 install autorom
!pip3 install 'gym[atari]' gym</p>
<h1 id="pip-install-upgrade-gymatari">!pip install --upgrade 'gym[atari]'</h1>
<p>!pip3 install --upgrade gym
!pip3 install autorom[accept-rom-license]
!pip3 install pydot
Let us test if it is working</p>
<div class="highlight"><pre><span></span><code><span class="err">!</span><span class="n">pip3</span> <span class="n">show</span> <span class="n">tensorflow</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>/bin/pip3:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import load_entry_point
Name: tensorflow
Version: 2.13.1
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author: Google Inc.
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /home/rl/.local/lib/python3.8/site-packages
Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, termcolor, typing-extensions, wrapt, tensorflow-io-gcs-filesystem
Required-by:
</code></pre></div>
<p>You should be able to see the location of your tensorflow. If you cannot you might need to do: sudo nano ~/.bashrc and append the tensorflow path as follows (be mindful to the python version, yours might be &gt; 3.6)</p>
<p>export PYTHONPATH=/home/user/.local/lib/python3.6/site-packages:$PYTHONPATH.</p>
<p>We can also check if our GPU is defined as follows.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.python.client</span><span class="w"> </span><span class="kn">import</span> <span class="n">device_lib</span>
<span class="nb">print</span><span class="p">(</span><span class="n">device_lib</span><span class="o">.</span><span class="n">list_local_devices</span><span class="p">())</span>

<span class="c1"># or</span>
<span class="err">!</span><span class="n">python3</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;import tensorflow as tf; print(tf.config.list_physical_devices(&#39;GPU&#39;))&quot;</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>2024-05-06 09:48:12.076221: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-05-06 09:48:17.750243: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-05-06 09:48:17.768049: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-06 09:48:21.351978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT


[name: &quot;/device:CPU:0&quot;
device_type: &quot;CPU&quot;
memory_limit: 268435456
locality {
}
incarnation: 8559295629388873333
xla_global_id: -1
]
2024-05-06 09:48:26.056521: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-05-06 09:48:26.108027: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-05-06 09:48:26.108689: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-06 09:48:27.028070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[]
</code></pre></div>
<p>To run this notebook on a remote Azure lab server check this <a href="https://docs.microsoft.com/en-us/azure/lab-services/class-type-jupyter-notebook#template-virtual-machine">link</a></p>
<p><strong>Reading</strong>:
The accompanying reading of this lesson is <strong>chapter 16</strong> of our text book available online <a href="http://incompleteideas.net/book/RLbook2020.pdf">here</a>. Please note that we explain the ideas of this topic from a practical perspective and not from a theoretical perspective which is already covered in the textbook.</p>
<p>This lesson deals with <a href="https://gym.openai.com/">gym openai</a>. OPenAI Gym provides a rich set of libraries and environments to try our algorithms on. These include the Atari games the DQN used in their Nature <a href="https://storage.googleapis.com/deepmind-media/DQN/DQNNaturePaper.pdf">paper</a> to show that Deep Reinforcement Learning can supersede human performance on Atari games with the <em>same</em> generic model that is used in <em>all</em> of the presented games. </p>
<p>This was a big and important breakthrough since, previously, RL applications stayed largely within simpler control environments and required, as it was customary at that time, manual feature extraction. So, when this paper showed that it is feasible to build an end-to-end RL model that can automatically extract useful features that can be used directly in an RL training algorithm without any human engineering or intervention, it was an important landmark in our field. Prior to that, there was the Tesauro Backgammon <a href="https://en.wikipedia.org/wiki/TD-Gammon">TDGammon</a> as another success story which used a neural network to train a model to learn to play backgammon (see the chapter for more details). </p>
<p>From that moment on, DeepMind went into a progressive trajectory of successful research and applications in the domain of deep reinforcement learning that reached an unprecedented level of beating the world champion in the game of Go see AlphaGo <a href="https://www.nature.com/articles/nature24270.epdf?author_access_token=VJXbVjaSHxFoctQQ4p2k4tRgN0jAjWel9jnR3ZoTv0PVW4gB86EEpGqTRDtpIz-2rmo8-KG06gqVobU5NSCFeHILHcVFUeMsbvwS-lxjqQGg98faovwjxeTUgZAUMnRQ">paper</a> and then moved on to create a generic architecture that is capable of self-playing to reach superhuman levels in chess, Go and shogi that they called AlphaZero. Contrary to AlphaGo, AlphaZero did not use any human knowledge to train the model, and it completely started from scratch and let the AI train itself by itself! see <a href="https://www.deepmind.com/blog/alphazero-shedding-new-light-on-chess-shogi-and-go">here</a>. </p>
<p>Note that even the replay idea is an old idea in RL it just got rehashed and done a bit differently inside a buffer that allows us to conduct learning in mini-batches similar to what we do in supervised learning (since this was tried and tested by the ML community and it is proven to work very well with backpropagation).
Yet, this idea was not new since other researchers have tried batches with RL. The paper's main flair is the impressive performance level that could be achieved via an adequately long period of training, a foot that has not been achieved before.
Note that the replay buffer dictates the choice of an off-policy algorithm i.e. Q-learning, since the replayed experience is old and the agent will be learning from a policy different to the one it pursues.</p>
<p>We expect this trajectory to continue and that RL with robotics will create the next wave of innovation that will hopefully change how we conduct our daily lives. We hope this will lead to positive changes and prosperity in the long run, but that does not prevent mistakes. You will tackle this ethical side in another module. For now, enjoy dealing with the revolutionary side of AI that will change the world!</p>
<p>Ok, let us get started...!</p>
<h1 id="openai-gym-classical-environment">OpenAI Gym Classical Environment</h1>
<p>We first tackle classical environments in OpenAI Gym as useful training for dealing with the library. In particular, we will start with their mountain car environment. We have already created our own class for this problem in the previous lesson, however, here, we will inherit their class, and we will override their rendering mechanism to be able to embed its visualisation in our notebook. </p>
<p>This is a useful exercise to familiarise ourselves with Gym and verify our findings in the previous lesson. Therefore, we will repeat some of the experiments we conducted in the previous lesson. No commentary is provided as it replicates previous experiments on our newly created class that depends on Gym.
Note that we have already set up our classes in previous lessons to be ready to integrate easily with Gym. We will show this in the following example.</p>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">cv2</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">floor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numpy.random</span><span class="w"> </span><span class="kn">import</span> <span class="n">rand</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.cm</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.animation</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">animation</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">gym</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gym.envs.classic_control</span><span class="w"> </span><span class="kn">import</span> <span class="n">MountainCarEnv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gym</span><span class="w"> </span><span class="kn">import</span> <span class="n">wrappers</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pygame</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ale_py</span><span class="w"> </span><span class="kn">import</span> <span class="n">ALEInterface</span>
<span class="n">ale</span> <span class="o">=</span> <span class="n">ALEInterface</span><span class="p">()</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">ale_py.roms</span><span class="w"> </span><span class="kn">import</span> <span class="n">Breakout</span>
<span class="c1"># ale.loadROM(Breakout)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)
[Powered by Stella]
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">losses</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">fashion_mnist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">clear_output</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Input</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.optimizers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">nbimporter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">Lesson14_EligibilityTraces_Prediction_Control</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
</code></pre></div>
<p>We start by showing you how to inherit from gym environment. We will do exactly what we did in the previous lesson regarding training a mountain car. This time we will utilise the openai gym environment rendering and </p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MountainCar</span><span class="p">(</span><span class="n">MountainCarEnv</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntiles</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">):</span>   <span class="c1">#  ω: position window, rd: velocity window</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>

        <span class="c1"># constants                          </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X0</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">Xn</span>  <span class="o">=</span> <span class="o">-</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">.5</span>       <span class="c1"># position range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Xv0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Xvn</span> <span class="o">=</span> <span class="o">-</span><span class="mf">.07</span><span class="p">,</span> <span class="mf">.07</span>      <span class="c1"># velocity range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">η</span> <span class="o">=</span> <span class="mi">3</span>                          <span class="c1"># we rescale by 3 to get the wavy valley/hill</span>

        <span class="c1"># for render()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X0</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">Xn</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>     <span class="c1"># car&#39;s position</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Xv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Xv0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Xvn</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>    <span class="c1"># car&#39;s speed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">η</span><span class="p">)</span>

        <span class="c1"># for state encoding (indexes)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ntiles</span>  <span class="o">=</span> <span class="n">ntiles</span>
        <span class="c1"># number of states is nS*nSd but number of features is nS+nSd with an econdoing power of 2^(nS+nSd)&gt;&gt;nS*nSd!</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nF</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nS</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntiles</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nA</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="c1"># for compatability</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Vstar</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># reset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xv</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># figure setup</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="c1">#plt.gcf().set_size_inches(self.figsize[0], self.figsize[1])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">s</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tilings</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">tilings</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">ntiles</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span>  <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">X0</span> <span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Xn</span>  <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">X0</span> <span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tilings</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">tilings</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">ntiles</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">xv</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Xv0</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Xvn</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Xv0</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xv</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">s_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">φ</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nF</span><span class="p">)</span>
        <span class="n">φ</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">()]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">φ</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">sv</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntiles</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">φ</span>

    <span class="c1"># for compatibility</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">S_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nF</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">isatgoal</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">&gt;=</span><span class="bp">self</span><span class="o">.</span><span class="n">Xn</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">a</span><span class="p">):</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xv</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">obs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_</span><span class="p">(),</span> <span class="n">r</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="p">{}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">visible</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pause</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">subplot</span><span class="o">=</span><span class="mi">131</span><span class="p">,</span> <span class="n">animate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">):</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">visible</span><span class="p">:</span> <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ax0</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">subplot</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">figsize</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">figsize</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">render</span><span class="p">())</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">animate</span><span class="p">:</span> 
            <span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span> <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">pause</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">time</span> <span class="n">sarsa</span> <span class="o">=</span> <span class="n">Sarsa</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">MountainCar</span><span class="p">(</span><span class="n">ntiles</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span> <span class="n">α</span><span class="o">=</span><span class="mf">.1</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">animate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">demoTR</span><span class="p">())</span><span class="o">.</span><span class="n">interact</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>CPU times: user 42.4 s, sys: 622 ms, total: 43 s
Wall time: 44.1 s
</code></pre></div>
<p><img alt="png" src="output_21_1.png" /></p>
<p>Note that we were only showing the end state in each episode and not the whole training process. We can make the process faster by not showing(animating) the training progress as we do below.</p>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">time</span> <span class="n">sarsa</span> <span class="o">=</span> <span class="n">Sarsa</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">MountainCar</span><span class="p">(</span><span class="n">ntiles</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span> <span class="n">α</span><span class="o">=</span><span class="mf">.1</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">demoTR</span><span class="p">())</span><span class="o">.</span><span class="n">interact</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>CPU times: user 27.5 s, sys: 347 ms, total: 27.9 s
Wall time: 28.3 s
</code></pre></div>
<p><img alt="png" src="output_23_1.png" /></p>
<p>No exploration</p>
<div class="highlight"><pre><span></span><code><span class="n">sarsa</span> <span class="o">=</span> <span class="n">Sarsa</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">MountainCar</span><span class="p">(</span><span class="n">ntiles</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span> <span class="n">α</span><span class="o">=</span><span class="mf">.3</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">ε</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">plotT</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">plotR</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">interact</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="output_25_0.png" /></p>
<div class="highlight"><pre><span></span><code><span class="n">sarsa</span> <span class="o">=</span> <span class="n">Sarsa</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">MountainCar</span><span class="p">(</span><span class="n">ntiles</span><span class="o">=</span><span class="mi">16</span><span class="p">),</span> <span class="n">α</span><span class="o">=</span><span class="mf">.3</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">ε</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">plotT</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">plotR</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">interact</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="output_26_0.png" /></p>
<div class="highlight"><pre><span></span><code><span class="n">sarsa</span> <span class="o">=</span> <span class="n">Sarsa</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">MountainCar</span><span class="p">(</span><span class="n">ntiles</span><span class="o">=</span><span class="mi">32</span><span class="p">),</span> <span class="n">α</span><span class="o">=</span><span class="mf">.3</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">ε</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">plotT</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">interact</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
</code></pre></div>
<p><img alt="png" src="output_27_0.png" /></p>
<div class="highlight"><pre><span></span><code><span class="n">MountainCarRuns</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>100%|██████████████████████████████████████████████| 20/20 [01:40&lt;00:00,  5.01s/it]
100%|██████████████████████████████████████████████| 20/20 [01:25&lt;00:00,  4.29s/it]
100%|██████████████████████████████████████████████| 20/20 [01:08&lt;00:00,  3.44s/it]
</code></pre></div>
<p><img alt="png" src="output_28_1.png" /></p>
<p>To run similar experiments that we did in the previous lesson we need to use the tiledMountainCar class.
Below we restate the tiledMountainCar class that we developed in the previous lesson. No changes here except that it inherits now from the new MountainCar cvlass that uses gym MountainCarEnv class. We could have avoided this by putting tiledMountainCar in a class factory function. This is left for you as an exercise.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">tiledMountainCar</span><span class="p">(</span><span class="n">MountainCar</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntilings</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">):</span> <span class="c1">#ntilings: is number of tiles</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ntilings</span> <span class="o">=</span> <span class="n">ntilings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntilings</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntiles</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ntiles</span><span class="o">+</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># the redundancy to mach the displacements of position(x) and velocity(xv)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nF</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">inds</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">s_tiling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntilings</span><span class="p">)</span>
        <span class="n">sv_tiling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntilings</span><span class="p">)</span>

        <span class="n">inds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">tiling</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ntilings</span><span class="p">):</span>
            <span class="n">s</span>  <span class="o">=</span> <span class="p">(</span><span class="n">s_tiling</span>  <span class="o">+</span> <span class="mi">1</span><span class="o">*</span><span class="n">tiling</span> <span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">ntilings</span>
            <span class="n">sv</span> <span class="o">=</span> <span class="p">(</span><span class="n">sv_tiling</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">tiling</span> <span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">ntilings</span>

            <span class="n">inds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tiling</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">sv</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">inds</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">s_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">φ</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inds</span><span class="p">():</span> 
            <span class="n">φ</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>

        <span class="k">return</span> <span class="n">φ</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">trange</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">SarsaOnMountainCar</span><span class="p">(</span><span class="n">ntilings</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="n">n</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>100%|████████████████████████████████████████████████| 5/5 [00:22&lt;00:00,  4.42s/it]
</code></pre></div>
<p><img alt="png" src="output_31_1.png" /></p>
<div class="highlight"><pre><span></span><code><span class="n">MountainCarRuns</span><span class="p">(</span><span class="n">runs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">IHTtiledMountainCar</span><span class="p">(</span><span class="n">ntilings</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">ntiles</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;with index hashed table for 8*8*8 tiles&#39;</span><span class="p">)</span>
<span class="n">MountainCarRuns</span><span class="p">(</span><span class="n">runs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">tiledMountainCar</span><span class="p">(</span><span class="n">ntilings</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">ntiles</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;with 8*8*8 tiles&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>100%|██████████████████████████████████████████████| 10/10 [01:12&lt;00:00,  7.21s/it]
100%|██████████████████████████████████████████████| 10/10 [01:00&lt;00:00,  6.00s/it]
100%|██████████████████████████████████████████████| 10/10 [00:50&lt;00:00,  5.10s/it]
100%|██████████████████████████████████████████████| 10/10 [01:42&lt;00:00, 10.27s/it]
100%|██████████████████████████████████████████████| 10/10 [01:25&lt;00:00,  8.56s/it]
100%|██████████████████████████████████████████████| 10/10 [01:17&lt;00:00,  7.72s/it]
</code></pre></div>
<p><img alt="png" src="output_32_1.png" /></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">IHTtiledMountainCar</span><span class="p">(</span><span class="n">tiledMountainCar</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iht_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">):</span> <span class="c1"># by default we have 8*8*8 (position tiles * velocity tiles * tilings)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nF</span> <span class="o">=</span> <span class="n">iht_size</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">s_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">φ</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nF</span><span class="p">)</span>
        <span class="n">inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">s_</span><span class="p">()</span><span class="o">!=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">φ</span><span class="p">[</span><span class="n">inds</span><span class="o">%</span><span class="bp">self</span><span class="o">.</span><span class="n">nF</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">φ</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">MountainCarTilings</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>100%|██████████████████████████████████████████████| 20/20 [01:31&lt;00:00,  4.58s/it]
100%|██████████████████████████████████████████████| 20/20 [01:24&lt;00:00,  4.25s/it]
100%|██████████████████████████████████████████████| 20/20 [01:25&lt;00:00,  4.30s/it]
100%|██████████████████████████████████████████████| 20/20 [01:36&lt;00:00,  4.82s/it]
100%|██████████████████████████████████████████████| 20/20 [01:56&lt;00:00,  5.85s/it]
</code></pre></div>
<p><img alt="png" src="output_34_1.png" /></p>
<p>As we can see we got identical results to the same experiments that we ran in the previous lesson.</p>
<h1 id="openai-gym-atari-games-environments">OpenAI Gym Atari Games Environments</h1>
<p>Now we are ready to move to our Atari environment. To be able to follow the logic it is better if you read the Nature paper since most tutorial follow the deep learning architecture that the paper presented. Note that the deep neural network architecture is just three CNNs, nevertheless the paper pioneered and showed the effectiveness of combing deep learning with reinforcement learning. The paper has few inventions such as the experience replay buffer and the batch training something which had not been done successfully before in RL in such a context. The main contribution is to prove that RL is generic enough to be applied to learn from images just as human learn to play a game. Note that the algorithm needed to be an off-policy because of the usage of the experience replay buffer. The use of experience replay means that the agent is learning its current policy from an old experience that stemmed from following an old policy (previous version of its current policy). </p>
<p>Note that in terms of theory we are still lagging to prove convergence of such approaches. This is where we can be uncertain which shadow of doubt on the ethical controllability of our own creation.</p>
<h2 id="atari-gym-wrapper">Atari Gym Wrapper</h2>
<p>Let us now build our own wrapper for Atari game so that we are able to apply Deep Q-Learning on the screen pixels coming from the environment. We have equipped our environment with necessary video storing as well as with pre-processing and to be able to handle the frames of the Gym environment. Note that we are dealing with environments that do not perform skipping to avoid the stochasticity associated with randomly applying actions. Therefore, we had to do the frame skipping in the wrapper class. It is also sufficient to deal with grey scale images not RGB since this will reduce the processing demands on our machines. Feel free to experiments with the GymEnv class to change its underlying preprocessing and or its assumptions.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">GymEnvi</span><span class="p">(</span><span class="n">Wrapper</span><span class="o">=</span><span class="n">gym</span><span class="o">.</span><span class="n">Wrapper</span><span class="p">):</span>

    <span class="k">class</span><span class="w"> </span><span class="nc">GymEnvi</span><span class="p">(</span><span class="n">Wrapper</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_name</span><span class="o">=</span><span class="s1">&#39;ALE/Pong-v5&#39;</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>   <span class="c1"># &#39;PongNoimgskip-v4&#39;</span>
                     <span class="n">nimgs_skip</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">nimgs_stack</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">img_size</span><span class="o">=</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">84</span><span class="p">),</span> 
                     <span class="n">video</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">animate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">saveimg</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

            <span class="c1"># if Wrapper==gym.Wrapper:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_name</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s1">&#39;rgb_array&#39;</span><span class="p">))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">nA</span> <span class="o">=</span> <span class="mi">3</span> <span class="k">if</span> <span class="s1">&#39;Pong&#39;</span> <span class="ow">in</span> <span class="n">env_name</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">env_name</span> <span class="o">=</span> <span class="n">env_name</span>
            <span class="c1"># seeding the game for consistency when testing</span>
            <span class="c1"># self.env.seed(seed)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">animate</span> <span class="o">=</span> <span class="n">animate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">saveimg</span> <span class="o">=</span> <span class="n">saveimg</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nimgs_skip</span> <span class="o">=</span> <span class="n">nimgs_skip</span>      <span class="c1"># how many imgs will be skipped to form one step</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">imgs_skip</span>  <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># a buffer to store last few imgs that will take their max</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">nimgs_stack</span> <span class="o">=</span> <span class="n">nimgs_stack</span>    <span class="c1"># how many imgs will be put together to form a one state (we use first and last only)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">img_size</span>    <span class="o">=</span> <span class="n">img_size</span>       <span class="c1"># (w,h)how much reduction will be applied on the original imgs</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">img_size_</span>   <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">img_size</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nimgs_stack</span><span class="p">))</span> <span class="c1"># extended dimension of state space</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">imgs_stack</span>  <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">nimgs_stack</span><span class="p">)</span>


            <span class="bp">self</span><span class="o">.</span><span class="n">nS</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># for compatibility</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">i</span> <span class="o">=</span> <span class="n">i</span>   <span class="c1"># video number</span>

            <span class="c1"># ineffective for compatibility </span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Vstar</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># for rendering and video</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ax0</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">video</span> <span class="o">=</span> <span class="n">video</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">video_imgs</span>  <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">video_imgs_</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># self.s holds the latest img *after* preprocessing (state/observation seen by the agent)</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">s</span> 

        <span class="c1"># self.img holds the latest img *before* preprocessing (will be used for videos)</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">a</span> <span class="ow">and</span> <span class="s1">&#39;Pong&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_name</span><span class="p">:</span> <span class="n">a</span><span class="o">+=</span><span class="mi">1</span> <span class="c1"># suitable for pong only</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">a</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># skip 4 imgs (apply same action) and stack last 2 imgs then take their max</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nimgs_skip</span><span class="p">):</span>
                <span class="n">img</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">+=</span> <span class="n">r</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">imgs_skip</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="p">:</span> <span class="k">break</span>

            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgs_skip</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">imgs_stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

            <span class="c1"># stack only the first and last imgs to save computation and to convey movement direction to the model</span>
            <span class="n">img_inds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nimgs_stack</span><span class="o">&gt;</span><span class="mi">1</span> <span class="k">else</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">imgs_stack</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">img_inds</span> <span class="p">])</span>

            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="p">,</span> <span class="p">{}</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">imgs_skip</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">imgs_stack</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

            <span class="c1"># reset the environment and retain its initial state (image) </span>
            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">imgs_skip</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

            <span class="c1"># now stack the same img n times for consistency with step()</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nimgs_stack</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">imgs_stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

            <span class="n">img_inds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nimgs_stack</span><span class="o">&gt;</span><span class="mi">1</span> <span class="k">else</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">imgs_stack</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">img_inds</span> <span class="p">])</span>

            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">img</span> 

        <span class="c1">#------------------------------------------render ✍️-------------------------------------------------</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">visible</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pause</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">subplot</span><span class="o">=</span><span class="mi">131</span><span class="p">,</span>  <span class="n">animate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">):</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">visible</span><span class="p">:</span> <span class="k">return</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">ax0</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">subplot</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">figsize</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">figsize</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

            <span class="c1"># saving it as a video if needed, note that we render only at the last few episode</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">video</span> <span class="ow">and</span> <span class="n">animate</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">video_imgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img</span><span class="p">)</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
                <span class="c1"># create the video at the end of the set of episodes</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">obsv</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_imgs</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_imgs_</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">obsv</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">Greys_r</span><span class="p">,</span> <span class="n">animated</span><span class="o">=</span><span class="kc">True</span><span class="p">)])</span>
                    <span class="n">anim</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">ArtistAnimation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ax0</span><span class="o">.</span><span class="n">figure</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_imgs_</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">repeat_delay</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
                    <span class="n">anim</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;atari</span><span class="si">%d</span><span class="s1">.mp4&#39;</span><span class="o">%</span><span class="bp">self</span><span class="o">.</span><span class="n">i</span><span class="p">)</span>
            <span class="n">img_inds</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nimgs_stack</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nimgs_stack</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">imgs_stack</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">img_inds</span><span class="p">])</span>

            <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">animate</span><span class="p">:</span>
                <span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">pause</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">GymEnvi</span>

<span class="n">GymEnv</span> <span class="o">=</span> <span class="n">GymEnvi</span><span class="p">()</span>
</code></pre></div>
<p>Let us create some handy function to play an Atari games and observe the states.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">play</span><span class="p">(</span><span class="n">ep</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">GymEnv</span><span class="p">(</span><span class="n">nimgs_stack</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> <span class="n">render</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span> <span class="c1"># try nframes_stack=5 it is fun!</span>
    <span class="k">for</span> <span class="n">ep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ep</span><span class="p">):</span>
        <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">done</span><span class="o">=</span><span class="kc">False</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
            <span class="n">s</span><span class="p">,</span><span class="n">r</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">render</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">pause</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">s</span> <span class="o">=</span> <span class="n">play</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="output_41_0.png" /></p>
<div class="highlight"><pre><span></span><code>(84, 84, 2)
</code></pre></div>
<h1 id="rl-with-deep-learning">RL with Deep Learning</h1>
<p>It is time to extend our basic MRP class to handle function approximation using deep neural networks.
Note that in their paper DeepMinds trained for 200M frames, we set the max_t_exp (used in stop_exp() function) to 2M due to hardware limitation. We can also make the stop_exp() tied to R-star that is specific to the game under consideration. For example, in Pong, we can set this to 18. This means that on average (for the last 100 or 200 games/episodes), the opponent could only score <em>only a max of 3</em> goals, and our agent scores the wining <em>21</em> goals.</p>
<h3 id="buffer-implementation">Buffer Implementation</h3>
<p>It is better to implement the buffer as queue because it guarantees an O(1) complexity for append() and pop() and it is preferred over the list which gives us a O(n) for adding and retrieving an item. In Python we can utilise the double queue structure which gives us the flexibility to add and retrieve from both ends of the queue. Below, we show a quick example. Note that the buffer will be overwritten when. the number of items exceeds its length. This is useful for us because we just want the buffer to overwritten with new experience after it s full and to be kept updated accordingly.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">deque</span>
<span class="n">buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">buffer</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>deque([1, 2, 3, 4], maxlen=5)
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">buffer</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>deque([3, 4, 5, 6, 7], maxlen=5)
</code></pre></div>
<h3 id="sampling-form-the-buffer">Sampling form the buffer</h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>

<span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[4, 6]
</code></pre></div>
<h3 id="buffer-with-complex-element-tuples">Buffer with Complex Element (Tuples)</h3>
<p>Let us assume that we have a set of tuples each consists of (s,a,sn). In this case we can add these tuples as is. Below we show an example, we have represented actions as integers but states/observations as string to help identifying them visually, but bear in mind that they are going to be a more complex entities such as images.</p>
<div class="highlight"><pre><span></span><code><span class="n">buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;2&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;3&#39;</span><span class="p">))</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;3&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;4&#39;</span><span class="p">))</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;4&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;5&#39;</span><span class="p">))</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;5&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;4&#39;</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">buffer</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>deque([(&#39;2&#39;, 1, &#39;3&#39;), (&#39;3&#39;, 2, &#39;4&#39;), (&#39;4&#39;, 2, &#39;5&#39;), (&#39;5&#39;, 1, &#39;4&#39;)], maxlen=4)
</code></pre></div>
<p>Now in order to sample we can directly sample from the buffer </p>
<div class="highlight"><pre><span></span><code><span class="n">batch</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[(&#39;2&#39;, 1, &#39;3&#39;), (&#39;5&#39;, 1, &#39;4&#39;), (&#39;3&#39;, 2, &#39;4&#39;)]
</code></pre></div>
<p>However, the above is not useful, usually we want to place all the actions and states and next states in their own list to feed them as a batch into a neural network. To put all states and actions together each in its own list we can use zip</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">):</span> <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>(&#39;2&#39;, &#39;5&#39;, &#39;3&#39;)
(1, 1, 2)
(&#39;3&#39;, &#39;4&#39;, &#39;4&#39;)
</code></pre></div>
<p>We can also convert them into a numpy array directly.</p>
<div class="highlight"><pre><span></span><code><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">)]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[array([&#39;2&#39;, &#39;5&#39;, &#39;3&#39;], dtype=&#39;&lt;U1&#39;),
 array([1, 1, 2]),
 array([&#39;3&#39;, &#39;4&#39;, &#39;4&#39;], dtype=&#39;&lt;U1&#39;)]
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;2&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;3&#39;</span><span class="p">))</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;3&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;4&#39;</span><span class="p">))</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;4&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;5&#39;</span><span class="p">))</span>
<span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;5&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="s1">&#39;4&#39;</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">buffer</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">sample</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span><span class="mi">3</span><span class="p">))]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>deque([(&#39;2&#39;, 1, &#39;3&#39;), (&#39;3&#39;, 2, &#39;4&#39;), (&#39;4&#39;, 2, &#39;5&#39;), (&#39;5&#39;, 1, &#39;4&#39;)], maxlen=4)
[array([&#39;5&#39;, &#39;2&#39;, &#39;3&#39;], dtype=&#39;&lt;U1&#39;), array([1, 1, 2]), array([&#39;4&#39;, &#39;3&#39;, &#39;4&#39;], dtype=&#39;&lt;U1&#39;)]
</code></pre></div>
<h2 id="deep-mrp">Deep MRP</h2>
<p>In this class we implement the basic functionality for dealing with creating, saving and loading deep learning models. In addition, we make these models the default functions used to obtain the value function via self.V_.
We also adjust the stope_exp criterion so that the algorithm stops when a specific averaged reward is achieved or when a specific <em>total</em> number of steps (self.t_ not self.t) have been elapsed. This means also that we free ourselves from the notion of an episode, so our model can run as many episodes as it takes to achieve this total number of steps. We still can assign episodes=x to store metrics for last y episodes where y&lt;x.
Note that nF is usually used in the Env(ironment) class but feature extraction is embedded the model itself in deep learning model so it is defined in the Deep_MRP class.</p>
<div class="highlight"><pre><span></span><code><span class="mi">200000</span><span class="o">%</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">2e6</span><span class="p">)</span><span class="o">*</span><span class="mf">.1</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>True
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">env</span><span class="o">=</span><span class="n">GymEnv</span><span class="p">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">nA</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>3
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Deep_MRP</span><span class="p">(</span><span class="n">MRP</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">env</span><span class="o">=</span><span class="n">GymEnv</span><span class="p">(),</span> 
                 <span class="n">γ</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span>
                 <span class="n">nF</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> 
                 <span class="n">R_star</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                 <span class="n">last</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                 <span class="n">buffer_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> 
                 <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> 
                 <span class="n">max_t_exp</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e6</span><span class="p">),</span>
                 <span class="n">load_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">print_</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kw</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span> <span class="n">γ</span><span class="o">=</span><span class="n">γ</span><span class="p">,</span> <span class="n">last</span><span class="o">=</span><span class="n">last</span><span class="p">,</span> <span class="n">print_</span><span class="o">=</span><span class="n">print_</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nF</span>           <span class="o">=</span> <span class="n">nF</span> <span class="c1"># feature extraction is integrated within the deep learning model not the env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">R_star</span>       <span class="o">=</span> <span class="n">R_star</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span>  <span class="o">=</span> <span class="n">buffer_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>   <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_</span><span class="o">=</span> <span class="n">load_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_t_exp</span>    <span class="o">=</span> <span class="n">max_t_exp</span> <span class="c1"># used to stop learning</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vN</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;V&#39;</span><span class="p">)</span>                      <span class="c1"># create V deep network</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vN</span><span class="p">,</span><span class="s1">&#39;V&#39;</span><span class="p">)</span> <span class="c1"># from earlier training proces</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vN</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">V_</span>

    <span class="c1">#-------------------------------------------Deep model related---------------------------</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net_str</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;model for </span><span class="si">{</span><span class="n">net_str</span><span class="si">}</span><span class="s1"> network is being loaded from disk........!&#39;</span><span class="p">)</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">Input</span><span class="p">((</span><span class="mi">84</span><span class="p">,</span><span class="mi">84</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="c1">#self.env.frame_size_)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x0</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nF</span><span class="p">,</span> <span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">net_str</span><span class="o">==</span><span class="s1">&#39;V&#39;</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">nA</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span> 
        <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">α</span><span class="p">),</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">net_str</span> <span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;weights for </span><span class="si">{</span><span class="n">net_str</span><span class="si">}</span><span class="s1"> network are being loaded from disk........!&#39;</span><span class="p">)</span>
        <span class="n">loaded_weights</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">net_str</span><span class="p">)</span>
        <span class="n">loaded_weights</span><span class="o">.</span><span class="n">assert_consumed</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;weights for V network are being saved to disk........!&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vN</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s1">&#39;V&#39;</span><span class="p">)</span>

    <span class="c1">#------------------------------------- value related 🧠-----------------------------------</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">V_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">!=</span><span class="mi">4</span><span class="p">:</span> 
            <span class="c1"># this needs to be tested to make sure it give us the required dim</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vN</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># prediction for one state for εgreedy to work well</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vN</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>  <span class="c1"># prediction for a batch of states, we copy to avoid auto-grad issues</span>

    <span class="c1"># ------------------------------------ experiments related --------------------------------</span>
    <span class="c1"># overriding: we do not specify a preset number of episodes to stop the experiments</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">stop_exp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ep</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">R_star</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">Rs</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">ep</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">R_star</span><span class="p">:</span> 
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;target reward is achieved in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">t_</span><span class="si">}</span><span class="s1"> steps!&#39;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_t_exp</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;max steps of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">t_</span><span class="si">}</span><span class="s1"> is reached and training is stopped, weights are being saved!&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_weights</span><span class="p">()</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="c1"># save model&#39;s weights at least 10 times during the life of the agent</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">t_</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">%</span><span class="nb">int</span><span class="p">(</span><span class="mf">.1</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">max_t_exp</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_weights</span><span class="p">()</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="c1"># stop_ep must be overriden because otherwise it will stope when max_t is reached</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">stop_ep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span> <span class="k">return</span> <span class="n">done</span>

    <span class="c1">#-------------------------------------------buffer related----------------------------------</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">allocate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">store_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">a</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">rn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">sn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">an</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">done</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">rn</span><span class="p">,</span> <span class="n">sn</span><span class="p">,</span> <span class="n">done</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># sample a set of batch_size tuples (each tuple has 5 items) without replacement </span>
        <span class="c1"># zip the tuples into one tuple of 5 items and convert each item into a np array </span>
        <span class="c1"># of size batch_size   </span>
        <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">experience</span><span class="p">)</span> <span class="k">for</span> <span class="n">experience</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))]</span>

        <span class="c1"># generate a set of indices handy for filtering, to be used in online()</span>
        <span class="n">inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">inds</span>
</code></pre></div>
<h2 id="deep-mdp">Deep MDP</h2>
<p>Now we create the Deep_MDP class which implements policy related functionality</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Deep_MDP</span><span class="p">(</span><span class="n">Deep_MRP</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">ε</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>  
                 <span class="n">εmin</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> 
                 <span class="n">εT</span><span class="o">=</span><span class="mi">200000</span><span class="p">,</span>    <span class="c1"># linear decay by default</span>
                 <span class="n">t_qNn</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>   <span class="c1"># update the target network every t_qNn steps</span>
                 <span class="n">create_vN</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kw</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">t_qNn</span> <span class="o">=</span> <span class="n">t_qNn</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">create_vN</span> <span class="o">=</span> <span class="n">create_vN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ε</span> <span class="o">=</span> <span class="n">ε</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">εmin</span> <span class="o">=</span> <span class="n">εmin</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">εT</span> <span class="o">=</span> <span class="n">εT</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">create_vN</span><span class="p">:</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>                        <span class="c1"># to create also vN, suitable for actor-critic</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">qN</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;Q&#39;</span><span class="p">)</span>                     <span class="c1"># create main policy network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qNn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;Q&#39;</span><span class="p">)</span>                     <span class="c1"># create target network to estimate Q(sn)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qN</span><span class="p">,</span><span class="s1">&#39;Q&#39;</span><span class="p">)</span> <span class="c1"># from earlier training proces</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qNn</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qN</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">qN</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">Q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q_</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_vN</span><span class="p">:</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">save_weights</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;weights for Q network are being saved to disk........!&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qN</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s1">&#39;Q&#39;</span><span class="p">)</span>
    <span class="c1">#------------------------------------- policies related 🧠-----------------------------------</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">Q_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">!=</span><span class="mi">4</span><span class="p">:</span> 
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">qN</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># prediction for one state for εgreedy to work well</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qN</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>  <span class="c1"># prediction for a batch of states, we copy to avoid auto-grad issues</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">Qn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sn</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">qNn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sn</span><span class="p">)</span>    
    <span class="c1">#-------------------------------------- 🔍 conditions -----------------------------------------</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">online_cond</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer_size</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">target_cond</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_qNn</span><span class="o">==</span><span class="mi">0</span>

    <span class="c1">#-------------------------------------- 🧠 deep nets updates ----------------------------------- </span>
    <span class="k">def</span><span class="w"> </span><span class="nf">update_before</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">update_after</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span> <span class="k">pass</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">update_online_net</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>    

    <span class="c1"># update the target network every now and then</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">update_target_net</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_cond</span><span class="p">():</span> 
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;assigning weights for target network.....&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qNn</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qN</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>


    <span class="c1">#------------------------------------- 🌖 online learning --------------------------------------       </span>
    <span class="k">def</span><span class="w"> </span><span class="nf">online</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="c1"># make sure the buffer is full before doing any update or sampling</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">online_cond</span><span class="p">():</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">update_before</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">update_target_net</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_online_net</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_after</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
</code></pre></div>
<h2 id="deep-q-learning-architecture">Deep Q-Learning Architecture</h2>
<p>Note that we need to set ε here otherwise it will be set by default to .1 in the parent class.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">DQN</span><span class="p">(</span><span class="n">Deep_MDP</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">α</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">):</span> 
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--------------------- 🧠  DQN is being set up 🧠 -----------------------&#39;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">α</span> <span class="o">=</span> <span class="n">α</span>

    <span class="c1">#------------------------------- 🌖 online learning ---------------------------------</span>
    <span class="c1"># update the online network in every step using a batch</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">update_online_net</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># sample a tuple batch: each componenet is a batch of items </span>
        <span class="c1">#(ex. s is a set of states, a is a set of actions)</span>
        <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">rn</span><span class="p">,</span> <span class="n">sn</span><span class="p">,</span> <span class="n">dones</span><span class="p">),</span> <span class="n">inds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span> 

        <span class="c1"># obtain the action-values estimation from the two networks </span>
        <span class="c1"># and make sure target is 0 for terminal states</span>
        <span class="n">Qs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="n">Qn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Qn</span><span class="p">(</span><span class="n">sn</span><span class="p">);</span> <span class="n">Qn</span><span class="p">[</span><span class="n">dones</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># now dictate what the target should have been as per the Q-learning update rule</span>
        <span class="n">Qs</span><span class="p">[</span><span class="n">inds</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">γ</span><span class="o">*</span><span class="n">Qn</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">rn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qN</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">Qs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># deal with the Grid states as images and learn from them to navigate it</span>
<span class="o">%</span><span class="n">time</span> <span class="n">deepqlearn</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">GymEnv</span><span class="p">(),</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_t_exp</span><span class="o">=</span><span class="mi">20000</span><span class="p">,</span> <span class="n">εT</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">buffer_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">interact</span><span class="p">()</span> 
</code></pre></div>
<div class="highlight"><pre><span></span><code>--------------------- 🧠  DQN is being set up 🧠 -----------------------
model for Q network is being loaded from disk........!
model for Q network is being loaded from disk........!
Model: &quot;model_4&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 84, 84, 1)]       0

 conv2d_12 (Conv2D)          (None, 20, 20, 32)        2080

 conv2d_13 (Conv2D)          (None, 9, 9, 64)          32832

 conv2d_14 (Conv2D)          (None, 7, 7, 64)          36928

 flatten_4 (Flatten)         (None, 3136)              0

 dense_8 (Dense)             (None, 512)               1606144

 dense_9 (Dense)             (None, 3)                 1539

=================================================================
Total params: 1679523 (6.41 MB)
Trainable params: 1679523 (6.41 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
assigning weights for target network.....
1/1 [==============================] - 0s 80ms/step
1/1 [==============================] - 0s 81ms/step
...
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># play pong and take the mean of the last n episodes but will keep going until R.mean() reaches R_star</span>
<span class="o">%</span><span class="n">time</span> <span class="n">deepqlearn</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">GymEnv</span><span class="p">(),</span><span class="n">R_star</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">max_t_exp</span><span class="o">=</span><span class="mi">200000</span><span class="p">,</span> <span class="n">εT</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">buffer_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">interact</span><span class="p">()</span> 
</code></pre></div>
<h2 id="double-dqn-learning">Double DQN Learning</h2>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">DDQN</span><span class="p">(</span><span class="n">DQN</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">α</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------- 🧠 Double DQN is being set up 🧠 ---------------------&#39;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">α</span> <span class="o">=</span> <span class="n">α</span>
    <span class="c1">#--------------------------- 🌖 online learning -----------------------------</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">update_online_net</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># sample a tuple batch: each componenet is a batch of items </span>
        <span class="c1">#(ex. s is a set of states, a is a set of actions) </span>
        <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">rn</span><span class="p">,</span> <span class="n">sn</span><span class="p">,</span> <span class="n">dones</span><span class="p">),</span> <span class="n">inds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="c1"># obtain the action-values estimation from the two networks </span>
        <span class="c1"># and make sure target is 0 for terminal states</span>
        <span class="n">Qs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="n">Qn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Qn</span><span class="p">(</span><span class="n">sn</span><span class="p">);</span> <span class="n">Qn</span><span class="p">[</span><span class="n">dones</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># now dictate what the target should have been as per the *Double* Q-learning update rule</span>
        <span class="c1"># this is where the max estimations are decoupled from the max action selections</span>
        <span class="n">an_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">(</span><span class="n">sn</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">Qs</span><span class="p">[</span><span class="n">inds</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">γ</span><span class="o">*</span><span class="n">Qn</span><span class="p">[</span><span class="n">inds</span><span class="p">,</span> <span class="n">an_max</span><span class="p">]</span> <span class="o">+</span> <span class="n">rn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qN</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">Qs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># play pong and take the mean of the last n episodes but will keep going until R.mean() reaches R_star</span>
<span class="o">%</span><span class="n">time</span> <span class="n">doubledeepqlearn</span> <span class="o">=</span> <span class="n">DDQN</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">GymEnv</span><span class="p">(),</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">buffer_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">interact</span><span class="p">()</span> 
</code></pre></div>
<h2 id="extracting-features-via-auto-encoders">Extracting Features via Auto-Encoders</h2>
<p>In this section we show how to use the latent variables of an auto-encoder in order to extract useful features from the frames grabbed from the games. This will allow us to apply previously covered algorithms that can be applied on linear models. For example we can take the latent variables and use them as the input for true online TD(<span class="arithmatex">\(\lambda\)</span>). 
Refer to keras <a href="https://www.tensorflow.org/tutorials/generative/autoencoder">auto-encoder</a> tutorial.</p>
<h3 id="build-a-dataset-from-a-game">Build a dataset from a game</h3>
<p>Let us collect a dataset from our game by assigning the max_t_exp to be as large as the buffer_size so that the games stops when the buffer is almost full.</p>
<div class="highlight"><pre><span></span><code><span class="n">dqn</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">GymEnv</span><span class="p">(),</span> <span class="n">buffer_size</span><span class="o">=</span><span class="mi">41000</span><span class="p">,</span> <span class="n">max_t_exp</span><span class="o">=</span><span class="mi">40000</span><span class="p">)</span><span class="o">.</span><span class="n">interact</span><span class="p">()</span> 
</code></pre></div>
<p>Now extract the data frames from the buffer.</p>
<div class="highlight"><pre><span></span><code><span class="n">experience</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">experience</span><span class="p">)</span> <span class="k">for</span> <span class="n">experience</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">dqn</span><span class="o">.</span><span class="n">buffer</span><span class="p">)]</span>
<span class="n">frames</span> <span class="o">=</span> <span class="n">experience</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;training data size&#39;</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;testing data size&#39;</span><span class="p">,</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<h2 id="conclusion">Conclusion</h2>
<p>In this lesson you saw how to deal with a continuous state space using function approximation and how to apply previous concepts on a more difficult control problems. We have built a wrapper class that allowed us to take advantage of the environments provided by OpenAI Gym library. We have duplicated what we have done in the previous lesson in order to 1. examine that our previous environment worked well, 2. see an example of how to deal with OpenAI Gym environment. </p>
<p>You have also seen how to combine deep learning with reinforcement learning to create a powerful model that is capable of learning from watching a game. This is really interesting since it opens up the possibility for enormous applications where an agent can watch and learn to arrive to a complex behaviour that allows it to accomplish a task or win a competition. </p>
<h1 id="units-conclusion">Unit's conclusion</h1>
<p>This lesson concludes our unit where we have studied important formulation of RL that we use a function approximation to represent the stare space which can be continuous and infinite.</p>
<p>We only expect that the interest is going to continue to grow and that RL with robotics will create the next wave of innovation that will hopefully change the way we conduct our daily lives. We hope that this will lead to positive changes and to prosperity in the long run but that does not prevent mistakes. You will tackle this ethical side in another module, for now enjoy dealing with revolutionary side of AI that will change the world!</p>
<p>Congratulations on completing this last unit on RL!</p>
<h2 id="discussion-and-activity">Discussion and Activity</h2>
<p>Read the following classic Nips <a href="https://deepmind.com/research/publications/2019/playing-atari-deep-reinforcement-learning">paper</a> and Nature <a href="https://storage.googleapis.com/deepmind-media/DQN/DQNNaturePaper.pdf">paper</a> and discuss it in the discussion forum.</p>
<h2 id="extra-resources">Extra Resources</h2>
<p>There are plenty of videos and resources which you can search online for.
- You may want to follow the following <a href="https://www.tensorflow.org/agents/tutorials/1_t_DQNnutorial#environment">tutorial</a> which shows how to deal with tensorflow on cart pole but the input is not the frames.
- You may then follow this <a href="https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html#hyperparameters-and-utilities">tutorial</a> which uses deep learning on the frames of a cart pole problem.</p>
<ul>
<li>You may find it useful to watch this <a href="https://www.youtube.com/watch?v=a5XbO5Qgy5w">video</a> for a Keras tutorial with RL, or this <a href="https://www.youtube.com/watch?v=NP8pXZdU-5U">video</a> for a pytorch tutorial with RL. </li>
<li>
<p>You may want to have a look at some <a href="https://neptune.ai/blog/best-reinforcement-learning-tutorials-examples-projects-and-courses">tutorials</a>.</p>
</li>
<li>
<p>You may find see this series of talks about the <a href="https://www.bbc.co.uk/sounds/play/m001216j">future of AI</a> by Stuart Russell interesting.</p>
</li>
<li>
<p>If you are intersted in self-driving cars, then:</p>
<ul>
<li>See the <a href="https://papers.nips.cc/paper/1988/file/812b4ba287f5ee0bc9d43bbf5bbe87fb-Paper.pdf">ALVIN</a> paper for an early stage vehicle road control neural network, it is an early precursor of the current road systems that control autonomous vehicle. A lot of the new systems retain some similarities with this systems. </li>
<li>See this <a href="https://youtu.be/2KMAAmkz9go">video</a> of the history of this system. </li>
<li>See this <a href="https://youtu.be/sRxaMDDMWQQ">video</a> lecture of the topic autonomous vehicle driving.</li>
</ul>
</li>
<li>
<p><strong>Carla Autonomous Vehicle Simulation</strong></p>
<ul>
<li>See this <a href="https://www.youtube.com/watch?v=pONr1R1dy88">video</a> for Carla simulation tutorial 1</li>
<li>See this <a href="https://www.youtube.com/watch?v=om8klsBj4rc">video</a> for Carla simulation tutorial 1</li>
</ul>
</li>
</ul>
<h2 id="your-turn">Your turn</h2>
<ol>
<li>
<p>try to apply the same concept on other simple environments provided by Gym such as the acrobot.</p>
</li>
<li>
<p>apply DQN on another Atari game such as SpaceInvaders or Breakout and report the score that you got in the discussion forum.</p>
</li>
<li>
<p>try to <em>think</em> of way to adopt a more complex neural network architecture that uses a more advanced CNN block in order to advance the state of the art in computer vision such as <a href="https://arxiv.org/pdf/2104.00298.pdf">EfficentNetV2</a>. As a starting point, we should note that this kind of neural networks is designed for classification. I.e. is there a way to deal with RL algorithms as a classification problem not a regression of estimating the value function v?.</p>
</li>
</ol>
<h2 id="challenge">Challenge++</h2>
<ol>
<li>check the implementation of the deep network in the <a href="https://keras.io/examples/rl/actor_critic_cartpole/">tutorial</a> and try to integrate it into the provided infrastructure.</li>
</ol>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright Abdulrahman Altahhan
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="../../javascript/tablecontentsoverride.js"></script>
      
        <script src="../../javascript/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>