
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Dr Abdulrahman Altahhan">
      
      
      
      
        <link rel="next" href="unit1/lesson1/lesson1.html">
      
      
      <link rel="icon" href="img/favicon.jpg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.4">
    
    
      
        <title>Reinforcement Learning and Robotics</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.8608ea7d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="css/extra.css">
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#welcome-to-reinforcement-learning-and-robotics" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
            
    <div id="versionIndicator"><b>Version:</b> 04.06.21.a</div>
    <img id="customlogo" src="../../img/logo.svg" alt="University of Leeds logo.">

          </div>
          
        </aside>
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="Reinforcement Learning and Robotics" class="md-header__button md-logo" aria-label="Reinforcement Learning and Robotics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Reinforcement Learning and Robotics
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Home
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="index.html" class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="unit1/lesson1/lesson1.html" class="md-tabs__link">
          
  
  Unit 1

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="unit2/lesson5/lesson5.html" class="md-tabs__link">
          
  
  Unit 2

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="unit3/lesson8/lesson8.html" class="md-tabs__link">
          
  
  Unit 3

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="unit4/lesson12/lesson12.html" class="md-tabs__link">
          
  
  Unit 4

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="unit5/lesson15/lesson15.html" class="md-tabs__link">
          
  
  Unit 5

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="unit6/lesson18/lesson18.html" class="md-tabs__link">
          
  
  Unit 6

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Reinforcement Learning and Robotics" class="md-nav__button md-logo" aria-label="Reinforcement Learning and Robotics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Reinforcement Learning and Robotics
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="index.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#rl-in-context-advantages-and-challenges" class="md-nav__link">
    <span class="md-ellipsis">
      RL in context: advantages and challenges
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#textbook" class="md-nav__link">
    <span class="md-ellipsis">
      Textbook
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-plan" class="md-nav__link">
    <span class="md-ellipsis">
      Module Plan
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    <span class="md-ellipsis">
      Table of Contents
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#code-structure-and-notebooks-dependecies" class="md-nav__link">
    <span class="md-ellipsis">
      Code Structure and Notebooks Dependecies
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installing-other-libraries-that-will-be-needed-later" class="md-nav__link">
    <span class="md-ellipsis">
      Installing other libraries that will be needed later
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Installing other libraries that will be needed later">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#available-themes" class="md-nav__link">
    <span class="md-ellipsis">
      available themes:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#better-readability-and-audibility" class="md-nav__link">
    <span class="md-ellipsis">
      Better Readability and Audibility
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Unit 1
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Unit 1
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit1/lesson1/lesson1.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1. Tabular Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit1/lesson2/lesson2.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2. K-Arm Bandit
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit1/lesson3/lesson3.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. MDP
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit1/lesson4/lesson4.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. ROS
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Unit 2
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Unit 2
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit2/lesson5/lesson5.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5. Dynamic Programming
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit2/lesson6/lesson6.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6. Monte Carlo
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit2/lesson7/lesson7.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7. Mobile Robots
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Unit 3
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Unit 3
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit3/lesson8/lesson8.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8. Temporal Difference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit3/lesson9/lesson9.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9. n-Step Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit3/lesson10/lesson10.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    10. Planning in RL(optional)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit3/lesson11/lesson11.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    11. Localisation and SLAM
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Unit 4
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Unit 4
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit4/lesson12/lesson12.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    12. Function Approximation Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit4/lesson13/lesson13.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    13. Linear Approximation for Prediction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit4/lesson14/lesson14.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    14. Linear Approximation for Control
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Unit 5
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Unit 5
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit5/lesson15/lesson15.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    15. Linear Approximation with Eligibility Traces(prediction and control)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit5/lesson16/lesson16.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    16. Nonlinear Approximation for Control
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit5/lesson17/lesson17.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    17. Application on Robot Navigation
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Unit 6
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Unit 6
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="unit6/lesson18/lesson18.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    18. Application on Games(optional)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#rl-in-context-advantages-and-challenges" class="md-nav__link">
    <span class="md-ellipsis">
      RL in context: advantages and challenges
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#textbook" class="md-nav__link">
    <span class="md-ellipsis">
      Textbook
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module-plan" class="md-nav__link">
    <span class="md-ellipsis">
      Module Plan
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#table-of-contents" class="md-nav__link">
    <span class="md-ellipsis">
      Table of Contents
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#code-structure-and-notebooks-dependecies" class="md-nav__link">
    <span class="md-ellipsis">
      Code Structure and Notebooks Dependecies
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installing-other-libraries-that-will-be-needed-later" class="md-nav__link">
    <span class="md-ellipsis">
      Installing other libraries that will be needed later
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Installing other libraries that will be needed later">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#available-themes" class="md-nav__link">
    <span class="md-ellipsis">
      available themes:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#better-readability-and-audibility" class="md-nav__link">
    <span class="md-ellipsis">
      Better Readability and Audibility
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<!-- By: Abdulrahman Altahhan, Feb 2025 -->

<h1 id="welcome-to-reinforcement-learning-and-robotics">Welcome to Reinforcement Learning and Robotics!</h1>
<p>Welcome to the Reinforcement Learning and Robotics module, where you learn the fundamentals of reinforcement learning(RL) with various simulaitons including robotics. The module focuses on RL as a general robust framework that allows us to deal with autonomous agent learning. </p>
<p>In each unit, you will learn essential RL ideas and algorithms and see how these can be implemented in simplified environments. Each lesson involves some reading material, along with some videos explaining these lessons. This will then be followed by running and experimenting with the Jupyter notebooks we provide, which implement the main ideas you have read and show you the RL algorithms you studied in action. It is essential that you read the material and engage with these notebooks in the way you see fit. This includes studying and running the provided code to gain insight into the covered algorithms, observing the algorithm convergence behaviour, experimenting with the hyperparameter and their effect on the agent's behaviour, and taking a turn to implement some concepts that were left out for you. </p>
<p>There are also some lessons that familiarise you with robotics as an application domain, which covers some simple concepts in robotics without delving deep into classical robotics, which is outside the scope of this module. Our units conclude with a simple, practical tutorial on utilising a simulated robot. You will use the provided code to control a simulated mobile robot called TurtleBot. The lessons are meant to gradually build your ability to deal with atonomous agents in a simplified environment. The final project will focus on comparing different RL solutions to solve a simulated robot navigation problem. We will provide you access to an Azure Ubuntu virtual machine already set up with ROS2 to run the sheets. You do not need to set up your own VM.</p>
<p>Reinforcement Learning (RL) is dedicated to acquiring an optimal policy to enhance agent performance. Traditionally, RL involves the agent seeking an optimal policy to maximise cumulative discounted rewards garnered by navigating various environmental states. While the agent is commonly perceived as a physical entity interacting with its surroundings, it can also encompass abstract systems, with states representing system configurations or settings. Notably, recent RL advancements have ventured into novel territories, such as optimising language models like LLMs for perplexity or other metrics.</p>
<p>In this module, our focus primarily revolves around simulated agents, aligning with the nature of our programme. However, the underlying principles remain universal and applicable across diverse scenarios. The concept of guiding learning through rewards is deeply ingrained in biological organisms, from complex human brains to single-cell organisms like amoebas, all driven by the innate urge to maximise survival and proliferation.</p>
<p>While RL offers tremendous efficacy when configured appropriately, it is susceptible to spectacular failure when its conditions are unmet. Its inherent stochasticity adds another layer of complexity, contributing to its volatile nature. Nonetheless, this volatility serves as a catalyst for researchers to delve deeper into understanding the governing rules of RL processes.</p>
<p>Our module adopts a pragmatic approach, aiming to provide you with a solid theoretical grounding in RL without overly delving into intricate mathematical details. Simultaneously, we will attempt to equip you with practical skills and techniques to harness RL's benefits effectively. This balanced approach ensures that you grasp RL's essence while gaining valuable real-world application tools.</p>
<video width="470" height="200" controls>
  <source src="/videos/Wecome Video.mp4" type="video/mp4">
  Wecome Video
</video>

<!-- <iframe src="https://leeds365-my.sharepoint.com/personal/scsaalt_leeds_ac_uk/_layouts/15/embed.aspx?UniqueId=2efc8e37-2e42-4b77-b694-b68994652e23&embed=%7B%22ust%22%3Atrue%2C%22hv%22%3A%22CopyEmbedCode%22%7D&referrer=StreamWebApp&referrerScenario=EmbedDialog.Create" width="640" height="360" frameborder="0" scrolling="no" allowfullscreen title="Wecome Video.mkv"></iframe> -->

<h2 id="rl-in-context-advantages-and-challenges">RL in context: advantages and challenges</h2>
<p>In our RL coverage, you will notice that we do not do classical robotics and we believe it is not the way to go except possibly for industrial robots. So, we do not need motion planning or accurate trajectory calculations/kinematics to allow the robot to execute a task, we simply let it interact with its environment and learn by itself how to solve the task and this is what reinforcement learning is about. In our coverage we also do not supervise or directly teach the robot, this type of interference is called imitation. </p>
<p>This is all great but what about challenges? Obviously, we still have several challenges to this approach. One is the number of experiments required to learn the task which can be numerous, which exposes the physical agents (real robots) to the risk of wear and tear due to repetition and can be very lengthy and tedious for the human that is supervising the task. This can be partially overcome by starting in simulation and then moving to a real robot with a technique called <a href="https://ai.googleblog.com/2021/06/toward-generalized-sim-to-real-transfer.html">sim-to-real</a> where we can employ GANs(generative adversarial neural networks).  The other challenge is the time required for training regardless whether it is in simulation or in real scenarios. </p>
<p>The origin of these problems is actually the exploitation/exploration needed by RL algorithms which is in the heart of what we will be exploring in all of our RL coverage. Reducing the amount of training required is important and remains an active area for research. One approach is via experience replay and the other is via eligibility traces as we shall see later.</p>
<h2 id="textbook">Textbook</h2>
<!-- The accompanying textbook of this and consecutive units is the Sutton Barto book Introduction to RL available online [here](http://incompleteideas.net/book/RLbook2020.pdf). You do not need to read the book's corresponding chapters, but they provide a further reading for you to understand the maetrial further and delve deeper into the subject.
Please note that we explain the ideas of RL from a practical perspective and not from a theoretical perspective which is already covered in the textbook. -->
<p>The primary textbook for this unit and the following ones is Introduction to Reinforcement Learning by Sutton and Barto, available online <a href="http://incompleteideas.net/book/RLbook2020.pdf">here</a>. While reading the corresponding chapters is not required, they serve as valuable supplementary material to enhance your understanding and explore the subject in greater depth.</p>
<p><strong>list of symbols</strong></p>
<ul>
<li><span class="arithmatex">\(v0\)</span>: denotes an initial value</li>
<li><span class="arithmatex">\(θ\)</span>: denotes a threshold</li>
<li><span class="arithmatex">\(nS\)</span>: denotes state space dimension </li>
<li><span class="arithmatex">\(nA\)</span>: denotes actions space dimension </li>
<li><span class="arithmatex">\(nR\)</span>: denotes rewards space dimension</li>
<li><span class="arithmatex">\(nU\)</span>: denotes the number of updates</li>
<li>
<p>goal: a terminal state</p>
</li>
<li>
<p><span class="arithmatex">\(r\)</span>: current step reward</p>
</li>
<li><span class="arithmatex">\(s\)</span>: current step state</li>
<li><span class="arithmatex">\(a\)</span>: current step action</li>
<li><span class="arithmatex">\(rn\)</span>: next step reward</li>
<li><span class="arithmatex">\(sn\)</span>: next step state</li>
<li>
<p><span class="arithmatex">\(an\)</span>: next step action</p>
</li>
<li>
<p><span class="arithmatex">\(α\)</span>: learning rate</p>
</li>
<li><span class="arithmatex">\(ε\)</span>: exploration rate</li>
<li><span class="arithmatex">\(dα\)</span>: decay factor for α</li>
<li><span class="arithmatex">\(dε\)</span>: decay factor for ε</li>
<li>
<p><span class="arithmatex">\(G(t+1,t+n)\)</span>: the return between time step t+1 and t+n</p>
</li>
<li>
<p>Rs: is the sum of rewards of an episode</p>
</li>
<li>Ts: is the steps of a set of an episode</li>
<li>Es: is the errors (RMSE) of an episode</li>
</ul>
<h2 id="module-plan">Module Plan</h2>
<p>We cover the tabular solution methods in the first three units, while approximate solution methods will be covered in subsequent units.</p>
<p>Tabular and approximate solution methods fall under two types of RL methods that we will attempt to deal with </p>
<ol>
<li>Prediction methods: AKA Policy Evaluation Methods that attempt to find the best estimate for the value-function <span class="arithmatex">\(V\)</span> or action-value function <span class="arithmatex">\(Q\)</span> for a policy <span class="arithmatex">\(\pi\)</span>.</li>
<li>Control methods: AKA Policy Improvement Methods that attempt to find the best policy <span class="arithmatex">\(\pi_*\)</span>, often by starting from an initial policy and then moving into a better and improved policy.</li>
</ol>
<p>Control methods, or policy improvement methods, in turn, falls under two categories:</p>
<ol>
<li>Methods that improve the policy via improving the action-value function <span class="arithmatex">\(Q\)</span></li>
<li>Methods that improve the policy directly <span class="arithmatex">\(\pi\)</span></li>
</ol>
<p>We start by assuming that the policy is fixed. This will help us develop algorithms predicting the state‘s value function (expected return). Then, we will move to the policy improvement methods, i.e., methods that help us compare our policy with other policies and move to a better policy when necessary. We then move to seamlessly integrating both for control case (policy and value iteration methods). Finally, we cover policy gradient methods that improve the policy directly.</p>
<p>Note that the guarantee from the policy-improvement theorem no longer applies when we move from the table representation of the value function for small state space to the parametric function approximation representation for large state space. This will encourage us to move to direct policy-improvement methods instead of improving the policy via improving the value function.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<p><strong>Unit 1</strong></p>
<ol>
<li><a href="unit1/lesson1/lesson1.html">Tabular Methods</a>  </li>
<li><a href="unit1/lesson2/lesson2.html">K-Arm Bandit</a>  </li>
<li><a href="unit1/lesson3/lesson3.html">MDP</a>  </li>
<li><a href="unit1/lesson4/lesson4.html">ROS</a>  </li>
</ol>
<p><strong>Unit 2</strong></p>
<ol>
<li><a href="unit2/lesson5/lesson5.html">Dynamic Programming</a>  </li>
<li><a href="unit2/lesson6/lesson6.html">Monte Carlo</a>  </li>
<li><a href="unit2/lesson7/lesson7.html">Mobile Robots</a>  </li>
</ol>
<p><strong>Unit 3</strong></p>
<ol>
<li><a href="unit3/lesson8/lesson8.html">Temporal Difference</a>  </li>
<li><a href="unit3/lesson9/lesson9.html">n-Step Methods</a>  </li>
<li><a href="unit3/lesson10/lesson10.html">Planning in RL (optional)</a>  </li>
<li><a href="unit3/lesson11/lesson11.html">Localisation and SLAM</a>  </li>
</ol>
<p><strong>Unit 4</strong></p>
<ol>
<li><a href="unit4/lesson12/lesson12.html">Function Approximation Methods</a>  </li>
<li><a href="unit4/lesson13/lesson13.html">Linear Approximation for Prediction</a>  </li>
<li><a href="unit4/lesson14/lesson14.html">Linear Approximation for Control</a>  </li>
</ol>
<p><strong>Unit 5</strong></p>
<ol>
<li><a href="unit5/lesson15/lesson15.html">Linear Approximation with Eligibility Traces (Prediction and Control)</a>  </li>
<li><a href="unit5/lesson16/lesson16.html">Nonlinear Approximation for Control</a>  </li>
<li><a href="unit5/lesson17/lesson17.html">Application on Robot Navigation</a>  </li>
</ol>
<p><strong>Unit 6</strong></p>
<ol>
<li><a href="unit6/lesson18/lesson18.html">Application on Games (optional)</a>  </li>
</ol>
<h2 id="code-structure-and-notebooks-dependecies">Code Structure and Notebooks Dependecies</h2>
<!-- Worksheets can be cloned and launched in GitHub Codespaces (repo is: AltahhanAi/RL-worksheets)
[![Open in GitHub Codespaces-](https://github.com/codespaces/badge.svg)](https://github.com/codespaces/new?repository=AltahhanAi/RL-worksheets) -->

<p>We have provided you with two <a download="RLlibrary.zip" href="/RLlibrary.zip">RL libraries</a> designed for this module. One has bespoke environments and one that has base RL classes that makes working with algorithms very easy and as close as it can be to just provide an update rule.</p>
<p><strong>Important note: Please place all worksheets in one folder, and inside this folder you must have the downloaded libraries folders (env and rl) to allow the imports to work appropriately</strong>.</p>
<h2 id="installing-other-libraries-that-will-be-needed-later">Installing other libraries that will be needed later</h2>
<!-- general -->
<div class="highlight"><pre><span></span><code>!pip install --upgrade pip
!pip install opencv-python
!pip install scikit-learn
!pip install matplotlib
!pip install tqdm 
</code></pre></div>
<!-- Better Readability -->
<div class="highlight"><pre><span></span><code>!pip install jupyterlab
!pip install jupyterthemes

!jt -t solarizedl -T -N  # -T, -N keeps the toolbar and header
</code></pre></div>
<h3 id="available-themes">available themes:</h3>
<ul>
<li>oceans16 </li>
<li>grade3 </li>
<li>chesterish </li>
<li>solarizedl </li>
<li>solarizedd </li>
<li>gruvboxl</li>
<li>!jt -r # resets back to the default theme</li>
</ul>
<h2 id="better-readability-and-audibility">Better Readability and Audibility</h2>
<p>For better readability and experience, please use Jupyter Lab or Vcode(if you are using Azure VM) to navigate between the different notebooks easily. If you want to use Jupyter Notebooks and not Jupyter Lab, we recommend increasing the cells' width for a better experience. We provided a function that increase your notebook width which is envoked automatically when you import an environment (grid particularly). You may want to utilise also the table of contents button in Jupetr Lab.
For better audibility of the provided videos please click on the <strong>'noise supression'</strong> button, you may want to speed up as per your need.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright Abdulrahman Altahhan
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": ".", "features": ["navigation.tabs", "navigation.sections"], "search": "assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="javascript/tablecontentsoverride.js"></script>
      
        <script src="javascript/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"></script>
      
        <script src="videos/my-video.mp4"></script>
      
    
  </body>
</html>